{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/alexis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, cross_val_predict, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Loading and processing data\n",
    "data = pd.read_json(open('./data.json', 'r'), lines=True)\n",
    "dataArray = data.values\n",
    "\n",
    "X = dataArray[:,1]\n",
    "Y_raw = dataArray[:,0]\n",
    "\n",
    "def f(dico, key):\n",
    "    return dico[key][0]\n",
    "\n",
    "fvect = np.vectorize(f)\n",
    "\n",
    "Y = fvect(Y_raw, 'label')\n",
    "Y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Pipeline of tests of different classifiers\n",
    "\n",
    "# Some classifiers\n",
    "clfs = {\n",
    "'CART': DecisionTreeClassifier(random_state=1),\n",
    "'RF': RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=10),\n",
    "'ID3': DecisionTreeClassifier(criterion = 'entropy', random_state=1),\n",
    "'MLP': MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(200,100),random_state=1),\n",
    "'KPPV': KNeighborsClassifier(n_neighbors=7),\n",
    "'BAGGING': BaggingClassifier(n_estimators=50,random_state=1),\n",
    "'ADABOOST': AdaBoostClassifier(n_estimators=50, random_state=1),\n",
    "'SVC': SVC(gamma='scale', decision_function_shape='ovo'),\n",
    "}\n",
    "\n",
    "# Test several classifiers with k-fold validation\n",
    "def run_classifiers(clfs,X,Y,pipeline, k=10):\n",
    "    # Preprocessing\n",
    "    Xproc = pipeline.fit_transform(X)\n",
    "    # Cross Validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    scoring = ['accuracy', \"roc_auc\"]\n",
    "    for i in clfs:\n",
    "        try:\n",
    "            clf = clfs[i]\n",
    "            print(\"\\n\\n======= {0} =======\".format(i))\n",
    "            scores = cross_validate(clf, Xproc, Y, cv=kf, scoring=scoring)\n",
    "            print(\"mean execution time : \", np.mean(scores['fit_time'] + scores['score_time']))\n",
    "            print(\"mean accuracy : \",np.mean(scores['test_accuracy']))\n",
    "            print(\"mean AUC : \",np.mean(scores['test_roc_auc']))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Preprocessing\n",
    "\n",
    "# Use of the stems of the words, and remove the stop words\n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# Preprocessing pipeline : Bag of Words + Tf-idf + SVD\n",
    "text_proc = Pipeline([('tfidf', TfidfVectorizer(min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "                      ('svd', TruncatedSVD(algorithm='randomized', n_components=300, random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= CART =======\n",
      "mean execution time :  7.241319370269776\n",
      "mean accuracy :  0.8593073731567108\n",
      "mean AUC :  0.878231987757443\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "mean execution time :  11.331089305877686\n",
      "mean accuracy :  0.9561024243939015\n",
      "mean AUC :  0.9698723274834247\n",
      "\n",
      "\n",
      "======= ID3 =======\n",
      "mean execution time :  11.477510404586791\n",
      "mean accuracy :  0.8649569482629342\n",
      "mean AUC :  0.8833485825762933\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "mean execution time :  52.45822868347168\n",
      "mean accuracy :  0.7982115096225944\n",
      "mean AUC :  0.8703570204064361\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "mean execution time :  83.30521392822266\n",
      "mean accuracy :  0.7218642464383904\n",
      "mean AUC :  0.8151230273348895\n",
      "\n",
      "\n",
      "======= BAGGING =======\n",
      "mean execution time :  246.72674889564513\n",
      "mean accuracy :  0.9422032366908273\n",
      "mean AUC :  0.9680307986738546\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n",
      "mean execution time :  28.636042404174805\n",
      "mean accuracy :  0.6831660584853787\n",
      "mean AUC :  0.7456159355708859\n",
      "\n",
      "\n",
      "======= SVC =======\n",
      "mean execution time :  142.12935581207276\n",
      "mean accuracy :  0.8576077230692327\n",
      "mean AUC :  0.9209331070442465\n"
     ]
    }
   ],
   "source": [
    "#%% Test\n",
    "run_classifiers(clfs,X,Y,text_proc, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Test the parameters of RandomForest\n",
    "\n",
    "parameters_RF = {'n_estimators' : (2,5,10,20,30,50,100,200),\n",
    "              'criterion': (\"gini\", \"entropy\"),\n",
    "              'max_depth' : (None, 8)}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1, n_jobs=10)\n",
    "\n",
    "X_proc = text_proc.fit_transform(X)\n",
    "gs_RF = GridSearchCV(rf, parameters_RF, cv=5, scoring=\"roc_auc\")\n",
    "gs_RF.fit(X_proc,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% We select RF as it gives the best results : we train the model on all data and save it\n",
    "\n",
    "final_pipe = Pipeline([('tfidf', TfidfVectorizer(min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "                      ('svd', TruncatedSVD(algorithm='randomized', n_components=300, random_state=1)),\n",
    "                      ('rf', RandomForestClassifier(n_estimators=200, random_state=1, n_jobs=10, criterion= 'entropy'))])\n",
    "\n",
    "final_pipe.fit(X, Y)\n",
    "joblib.dump(final_pipe, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% We save a small model which stil give good results for size reasons\n",
    "\n",
    "small_pipe = Pipeline([('tfidf', TfidfVectorizer(min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "                      ('svd', TruncatedSVD(algorithm='randomized', n_components=300, random_state=1)),\n",
    "                      ('rf', RandomForestClassifier(n_estimators=5, random_state=1, criterion= 'gini'))])\n",
    "\n",
    "small_pipe.fit(X, Y)\n",
    "joblib.dump(small_pipe, 'small_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
